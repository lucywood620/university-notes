\documentclass{article}[18pt]
\input{../../../../format}
\lhead{Networks and Systems - Compiler Design}
\newtheorem{theorem}{Theorem}

\begin{document}
\begin{center}
\underline{\huge Formal Languages and Grammars}
\end{center}
\section{Formal Languages}
Basic concepts of any formal language:
\begin{itemize}
	\item Alphabet $\Sigma$ = set of all possible symbols
	\item Sequence (or word) $\alpha$ = string of symbols
	\item Language = Particular set of sequences
\end{itemize} 
Further concepts:
\begin{itemize}
	\item Syntax: which sequences belong to the language
	\item Semantics: the meaning of these sequences
\end{itemize}
In the context of programming languages:
\begin{itemize}
	\item Sequences in the formal language are all valid program codes
\end{itemize}
If a language L has a finite number of sequences it is described by listing all sequences\\
If it has an infinite number of sequences it is represented with more complex set notation or with a set of substitution rules
\section{Formal Grammars}
\begin{definition}[Formal Grammar]
	A finite way of describing an infinite number of strings\\
	Given by a start symbol and a set of production rules
\end{definition}

\begin{definition}[Grammar]
A quadruple $(V_T,V_N,P,S)$ where:
\begin{itemize}
	\item $V_T$ is a set of terminal symbols (or terminals)
	\item $V_N$ is a set of non-terminal symbols (or terminals)
	\item $P$ is a set of productions (or rules)
	\item S is the start symbol (which is a non-terminal)
\end{itemize}
\end{definition}
$V=V_T\cup V_N$ is the set of all symbols where $V_T\cap V_N=\varnothing$
\subsection{Notation}
\begin{itemize}
	\item Non terminals: Capital letters
	\item Terminals: Lower case letters
	\item Sequences (strings): Greek letters
	\item Productions have the form: $\alpha \rightarrow \beta$
	\begin{itemize}
		\item $\alpha$ and $\beta$ are strings of both terminals and non-terminals
		\item $\alpha$ lies in $VY^+$ (it has at least one non-terminal)
		\item $\beta$ lies in $V^*$ (i.e. can also be the empty string $\epsilon$)
	\end{itemize}
	\item Whenever we have two rules $\alpha\rightarrow \beta_1, \alpha\rightarrow \beta_2$ we write equivalently $\alpha \rightarrow \beta_1|\beta_2$
\end{itemize}
\subsection{Example}
$$L_4=\{a^mb^n|m,n\geqslant 0\}$$
Grammar for this language: $G_4=\{ \{a,b\},\{S,A,B\},P,S\}$ where P includes:\\
$S\rightarrow AB$\\
$A\rightarrow a A$\\
$A\rightarrow\epsilon$\\
$B\rightarrow bB$\\
$B\rightarrow \epsilon$\\
Or equivalently
$S\rightarrow AB$\\
$A\rightarrow aA | \epsilon$\\
$B\rightarrow bB | \epsilon$
$$S\rightarrow AB \rightarrow aAB \rightarrow aaAB \rightarrow aaaAB \rightarrow aaaB \rightarrow aaabB \rightarrow aaabbB \rightarrow aaabb$$
Or in short:
$$S\xrightarrow[+]{G_4}aaabb$$
\section{Language generated by a grammar}
$$L(G)=\{\alpha\in V^*_T| S\xrightarrow[+]{G} \alpha \}$$
A non-terminal N is called
\begin{itemize}
	\item \textbf{Left-recursive} if starting with $N$, we can produce a string that starts again with $N$
	\begin{itemize}
		\item e.g. $N\rightarrow Nab$
	\end{itemize}
	\item \textbf{Nullable} if starting with N, we can produce $\epsilon$
	\begin{itemize}
		\item e.g. $N\rightarrow aNb | \epsilon$0
	\end{itemize}
	\item \textbf{Useless} if starting with $N$, we can never produce a string consisting only of terminals
	\begin{itemize}
		\item e.g. $N\rightarrow aN | bN$
	\end{itemize}
\end{itemize}
\section{The Chomsky Hierarchy}
\begin{definition}[Chomsky Hierarchy]
The classes of grammars we obtain by restricting the types of productions that can appear
\end{definition}
\textbf{Type 0} grammars - The set of all grammars\\
\textbf{Type 1} (or context sensitive) grammars
\begin{itemize}
	\item The grammars that have only productions of the form $\alpha \rightarrow \beta$, where $|\alpha| \geqslant |\beta|$
\end{itemize}
\textbf{Type 2} (or context free) grammars:
\begin{itemize}
	\item The context sensitive grammars, in which the left part of each production has one non terminal
	\item e.g. $A\rightarrow BaA$
\end{itemize}

\textbf{Type 3} (or regular) grammars
\begin{itemize}
	\item The context free grammars, in which all productions have one of the forms:
$$A\rightarrow a$$
$$A\rightarrow aB$$
	\item where B can also be equal to A. They are also called right linear grammars
\end{itemize}
Equivalent definition of a type 3 (regular) grammars:
\begin{itemize}
	\item All productions have one of the forms
	$$A\rightarrow a$$
	$$A\rightarrow Ba$$
	\item They are also called left linear grammars
\end{itemize}
The chomsky hierarchy also classifies the languages generated by these grammars
\section{Regular Expressions}
Regular expressions over an alphabet $\Sigma$ (recursive definition):
\begin{itemize}
	\item If any element of $\Sigma$ is a regular expression (also the empty string $\epsilon$)
	\item If P and Q are regular expressions, then the following are as well:
	\begin{itemize}
		\item PQ, i.e. the concatenation of P and Q
		\item $P|Q$ i.e. the disjunction of P and Q (that is: P or Q)
		\item $P^*$ i.e. Kleene star of P (zero or more copies of P)
	\end{itemize}
\end{itemize}
\begin{theorem}
	Regular grammars generate exactly regular expressions
\end{theorem}
Context free and regular languages are very useful in describing programming languages\\
\\
Regular grammars:
\begin{itemize}
	\item Many "local" features of a programming language can be expressed by regular expressions, e.g. constants, strings, identifiers
	\item A regular expression describing an identifier:
	$$L(L'|D)^*$$
	Here:
	\begin{itemize}
		\item L is the set of all letters
		\item $L'=L\cup \{\_\}$ is the set of all letters, including '\_'
		\item D is the set of all digits
	\end{itemize}
\end{itemize}
\section{Context Free Grammars}
\begin{itemize}
	\item Many syntactic properties of a programming language can be expressed by a context free grammar
	\item e.g. the pattern of matching brackets of arbitrary length 
	\item This can't be expressed by a regular expression but by this context free grammar
\end{itemize}
$$S\rightarrow (S)$$
$$S\rightarrow SS$$
$$S\rightarrow \epsilon$$
\section{Calling Graph}
Many algorithms in compiler construction first collect some basic data items then apply some rules to them to:
\begin{itemize}
	\item Extend the known information about these data items
	\item Draw more general conclusions about them
\end{itemize}
These "information-improving" algorithms:
\begin{itemize}
	\item Share a common structure
	\item Although they seem different
\end{itemize}
Basic example: the calling graph of a program
\begin{itemize}
	\item Directed graph with a node for each procedure
	\item Edge from A to B, whenever A calls
\end{itemize}
An example of why we need to find the calling graph is to find out which procedures:
\begin{itemize}
	\item Are recursive
	\item Can be expanded in-line inside another procedure
\end{itemize}
\section{Regular Definition}
\begin{definition}[Regular Definition]
	A sequence of definitions of the form
	$$
	\begin{array}{l}{d_{1} \rightarrow r_{1}} \\ {d_{2} \rightarrow r_{2}} \\ {\quad \cdots} \\ {d_{k} \rightarrow r_{k}}\end{array}
	$$
	Where:
	\begin{itemize}
		\item Each $d_i$ is different and not in $\Sigma$
		\item Each $r_i$ is a regular expression in $\Sigma \cup \{r_1,r_2,...,r_{i-1}\}$
	\end{itemize}
\end{definition}
We avoid recursive definitions by sequentially "eliminating" all $d_i$'s, thus if we can write a set of regular expressions as a regular definition, then we have no recursive definitions


\end{document}